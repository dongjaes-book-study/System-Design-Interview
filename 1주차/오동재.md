# 1. 사용자 수에 따른 규모 확장성

# 💽 데이터 베이스

## NoSQL을 사용을 고려해야하는 경우

- latency가 중요한 경우
- 비정형(unstructured) 데이터를 다루는 경우
- 데이터(JSON, XML 등)를 직렬화(serialize)하거나 역직렬화(deserialize)만 하면 되는 경우
- 아주 많은 양의 데이터를 저장할 필요가 있는 경우

## 데이터 베이스 다중화

1. master-slave

## 데이터 베이스 수평적 확장

수직적 확장으로는 하드웨어의 한계와 SPOF를 극복하기 힘듦. 그리고 비쌈 ⇒ 샤딩을 이용한 수평적 확장

### 샤딩시 고려할 점

- 데이터 재 샤딩
- celebrity 문제
- join and de-normalization

## 캐시

보통 웹서버(?)랑 DB사이에 둠

### 캐시 사용시 유의할 점

- expire 정책
- **consistency** : 원본과 캐시 사본의 일관성을 유지해야 함. 원본 갱신 연산과 캐시 갱신 연산이 단일 트랜잭션이 아닌 경우 일관성이 깨질 수 있음 ⇒ [https://nymets.medium.com/번역-scaling-memcache-at-facebook-9c67f9e61282](https://nymets.medium.com/%EB%B2%88%EC%97%AD-scaling-memcache-at-facebook-9c67f9e61282)
- 캐시 서버를 한 대만 두면 SPOF일 수도

### CDN 사용 시 고려해야 할 사항

- 비용
- expire 정책
- **CDN 장애에 대한 대처 방안** : CDN 자체가 죽었을 경우 원본 서버에 직접 접근하는 등의 대안 이 있어야 함

<aside>
💡 동적 콘텐츠 캐싱? (책 이외의 내용)

</aside>

# 👨‍👨‍👦 스케일 아웃

## 로드밸런서

- 스케일 아웃, failover정책 쉬워짐

### sticky session

## Stateless

상태를 DB or Memcach 등 다른 곳에 보관해둠

## geoDNS-routing

> 지리적으로 가장 가까운 데이터 센터로 라우팅해주는 기술

### geoDNS-routing시 고려할 점

- 가까운 데이터 센터 IP 찾기
- 데이터 동기화 : 각 데이터 센터의 데이터가 동기화되어있어야 함

# 질문

Q. 데이터베이스 master-slave가 실제로 어떻게 이루어지는지. CQRS를 구현하는 거 같은데 그게 어떻게 이루어지는지 데이터베이스가 3개 있다고 하면 그 위에 프록시가 있어서 거기서 query문을 보고 read인지 create인지 판단해서 create는 master한테 read는 slave한테 라우팅해주나? 구체적인 구현은 mysql, mongoDB, mariaDB등 엔진마다 다른가? 얘를 들어 atlas에서는 replicaset을 자동으로 제공하는데 어떻게 구현하는지 궁금해

A. 엔진마다 다르다고 하고 표준 규격이 있는 지는 모르겠음

Q. 단일데이터베이스에서 트래픽 병목때문에 실제로 문제를 직면한 경험이 있는 분이 있을까요?

A.

Q. 샤딩을 실제로 사용해보신 분이 있는지, celebrity문제 등을 해결한 적이 있는지 해결했다면 어떻게 해결했는지

A.

Q. geoDNS vs GSLB

A. GSLB는 geoDNS를 포함해 더 넓은 범위의 기술을 제공함. 위치뿐 아니라 트래픽, 서버의 상태, 응답 시간 등 다양한 요소를 고려해 라우팅해줌

# 2. 개략적인 규모 추정

# latency 관련 상식

- 메모리는 빠르지만 디스크는 아직도 느리다
- 디스크 탐색(seek)은 가능한 피하라
- 단순한 압축 알고리즘은 빠르다
- 데이터를 인터넷으로 전송하기 전에 가능하면 압축하라
- 데이터 센터는 보통 여러 지역에 분산되어 있고, 센터들 간에 데이터를 주고받는 데는 시간이 걸린다

# 질문

Q. 개략적인 규모 추정을 실제로 파악하고 설계에 들어간 경험이 있는지

# 3. 시스템 설계 면접 공략법

# 4단계 접근법

1. 문제 이해 및 설계 범위 확정 (3~10분)
   1. 질문을 통해 문제의 요구사항을 정확히 이해하자
2. 개략적인 설계안 제시 및 동의 구하기 (10~15분)
   1. 여러 방안을 제시해라
3. 상세 설계 (10~25분)
   1. 각 컴포넌트에 대해 설명하고 주요 컴포넌트에 대해 자세히 설명하라
4. 마무리 (3~5분)

# 4. 처리율 제한 장치의 설계

# 처리율 제한 장치 위치

- 미들웨어 직접 구현
- 3rd party 미들웨어 사용 : 인력이 없으면 이게 맞음
- 백엔드 서버 : msa인 경우 백엔드 중 api gateway가 있을 수 있고 여기 설계해도 됨.

# 처리율 제한 알고리즘 종류

### 1. 토큰 버킷

- 토큰 공급기가 토큰을 공급하고 오버플로된 토큰은 버림
- 버킷 크기와 토큰 공급률이라는 두 인자를 적절히 튜닝하는 것이 까다로움

### 2. 누출 버킷

- 두 개의 인자가 있음 : 버킷 크기(큐 사이즈), outflow rate(지정된 시간당 몇 개의 항목을 처리할지)

<aside>
💡 그럼 outflow에 따라서 모든 요청이 비동기로 처리됨? 바로 처리되지 않고?

</aside>

### 3. 고정 윈도 카운터

- 시간당 처리될 수 있는 요청을 제한해놓음
- 경계 부근에서 예상보다 많은 양의 데이터를 처리할 수 있음

### 4. 이동 윈도 로그

- 요청의 timestamp를 로그에 추가하고 새로운 요청이 들어오면 만료된 timestamp는 제거함.
  여기서 만료란 새 timestamp를 마지막으로 하는 윈도에 포함되지 않는 것들을 의미함
- 로그를 다 남기니까 메모리를 조금 많이 사용함

<aside>
💡 그럼 요청을 계속 하면 아무 요청도 처리되지 않는 거 아닌가?

</aside>

### 5. 이동 윈도 카운터

- `현재 윈도의 요청 수 + (직전 윈도의 요청 수 x 이동 윈도와 직전 윈도의 겹치는 비율)` 를 사용함. 해당 값이 설정해놓은 값보다 작으면 요청을 처리하고 크면 처리하지 않음
- 직전 윈도의 트래픽이 균등하다고 가정하기때문에 조금 느슨하게 트래픽을 제한하지만 클라우드플레어의 실험 결과 40억 요청 중 잘못되게 버려진 요청은 0.003%에 불과했다고 함

# 아키텍처

카운터는 redis 등에 보관함

### 처리율 제한 장치가 사용하는 HTTP 헤더

- X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청의 수
- X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-Retry-After : 한도 제한에 거리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지

## 분산 환경에서의 아키텍처

- race condition
  - lock
  - Lua script
  - redis sorted set
- synchronization
  - sticky session : 확장성이 낮고 유연하지 않음
  - 중앙 집중형 테이터 저장소
- 성능최적화
  - 엣지 서버 : 가까운 서버를 찌르게 해서 개선
  - 일관성 모델(eventual consistency model)
